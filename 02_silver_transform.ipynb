{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "849b566d-1b04-4697-8980-557891147abf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver_output_path = \"abfss://datalake@stetlprojectdeveus.dfs.core.windows.net/silver/employee/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e86eeda-adc7-4c85-8e79-d10efa777e47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\n",
    "  \"fs.azure.account.key.stetlprojectdeveus.dfs.core.windows.net\",\n",
    "  dbutils.secrets.get(scope=\"kv-etl-scope\", key=\"storage-account-key\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d2fd5e7-436d-43d1-8ee1-c5988442d0e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_input_path = \"abfss://datalake@stetlprojectdeveus.dfs.core.windows.net/bronze/\"\n",
    "\n",
    "df_bronze_data = spark.read.format(\"delta\").load(bronze_input_path)\n",
    "\n",
    "display(df_bronze_data)\n",
    "df_bronze_data.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a8a323e-b30b-4f14-9c4c-4cd9e788455e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_silver = df_bronze_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91f847d9-26bb-4c19-898a-344571a3aac7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_silver = df_bronze_data.dropDuplicates([\"Employee_ID\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d3531a7-38cd-4f8c-be23-afd8ce52ee04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_silver = df_silver.filter((col(\"Age\") >= 16) & (col(\"Age\") <= 70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e1af70e-0bee-491c-9f56-d1c046be6cd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Example: If salary is null or less than 0, set it to 0 (or remove row)\n",
    "df_silver = df_silver.withColumn(\n",
    "    \"Monthly_Salary\",\n",
    "    when((col(\"Monthly_Salary\").isNull()) | (col(\"Monthly_Salary\") < 0), 0)\n",
    "    .otherwise(col(\"Monthly_Salary\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "533cc6ad-e05f-4909-8fd9-2bd99212bce0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower, trim\n",
    "\n",
    "df_silver = df_silver.withColumn(\n",
    "    \"Education_Level\",\n",
    "    trim(lower(col(\"Education_Level\")))  # e.g., \"high school\", \"bachelor\", \"master\", \"phd\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cee0dcfd-2894-44ca-ac31-7f19f75ccc62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_silver = df_silver.withColumn(\n",
    "    \"Education_Level\",\n",
    "    when(col(\"Education_Level\") == \"high school\", \"High School\")\n",
    "    .when(col(\"Education_Level\") == \"bachelor\", \"Bachelor\")\n",
    "    .when(col(\"Education_Level\") == \"master\", \"Master\")\n",
    "    .when(col(\"Education_Level\") == \"phd\", \"PhD\")\n",
    "    .otherwise(\"Other\")  # fallback for unknown\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "339d0a17-a4c7-4913-b787-9c691de358cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, to_date\n",
    "\n",
    "cutoff_date = to_date(lit(\"2025-12-31\"))\n",
    "df_silver = df_silver.withColumn(\n",
    "    \"Hire_Date\",\n",
    "    when(col(\"Hire_Date\") > cutoff_date, lit(None).cast(\"timestamp\"))\n",
    "    .otherwise(col(\"Hire_Date\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d7a1e09-c72d-4a6f-8065-95daaadedbbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_silver = df_silver.withColumnRenamed(\"Resigned\", \"HasResigned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4872d90d-cb04-4b47-8947-7ff663801e19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, col\n",
    "\n",
    "df_silver = df_silver.withColumn(\n",
    "    \"Hire_Date\", \n",
    "    to_date(col(\"Hire_Date\"))   # or specify a format: to_date(col(\"Hire_Date\"), \"yyyy-MM-dd\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b4d0ed0-6f48-4871-ad71-b1d561d0667c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# review all the transformation\n",
    "display(df_silver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc3f5f59-d230-4fe4-abc7-ff1cac4cea93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver_output_path = \"abfss://datalake@stetlprojectdeveus.dfs.core.windows.net/silver/\"\n",
    "\n",
    "df_silver.write \\\n",
    "    .format(\"parquet\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(silver_output_path)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_silver_transform",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
